{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import xgboost\n",
    "import pickle\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loading data :\n",
    "types_train={\"Store\": \"int\", \"DayOfWeek\": \"int\", \"Date\": \"str\", \"Customers\": \"int\", \"Open\": \"int\",\n",
    "             \"Promo\": \"int\", \"StateHoliday\": \"str\", \"SchoolHoliday\": \"int\", \"Sales\": \"int\"}\n",
    "types_store={\"Store\": \"int\", \"StoreType\": \"str\", \"Assortment\": \"str\",\"Promo2\":\"int\"}\n",
    "train = pd.read_csv(\"train.csv\", parse_dates=[2], dtype=types_train)\n",
    "store = pd.read_csv(\"store.csv\",dtype=types_store) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xc230cf8>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmUAAAEuCAYAAADP+GUVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wfOHAN5wQ2H/AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc01d550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = train[train[\"Open\"] != 0]\n",
    "train = train[train[\"Sales\"] > 0]\n",
    "f,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\n",
    "train.Sales.hist(bins=20,ax=ax1)\n",
    "np.log(train.Sales).hist(bins=20,ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#types_test={\"Id\" : \"int\", \"Store\": \"int\", \"DayOfWeek\": \"int\", \"Date\": \"str\", \"Open\": \"int\",\n",
    "            #\"Promo\": \"int\", \"StateHoliday\": \"str\", \"SchoolHoliday\": \"int\"}\n",
    "test = pd.read_csv(\"test.csv\",parse_dates=[3])\n",
    "test.fillna(1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store            0\n",
      "DayOfWeek        0\n",
      "Date             0\n",
      "Sales            0\n",
      "Customers        0\n",
      "Open             0\n",
      "Promo            0\n",
      "StateHoliday     0\n",
      "SchoolHoliday    0\n",
      "dtype: int64 Id               0\n",
      "Store            0\n",
      "DayOfWeek        0\n",
      "Date             0\n",
      "Open             0\n",
      "Promo            0\n",
      "StateHoliday     0\n",
      "SchoolHoliday    0\n",
      "dtype: int64 Store                          0\n",
      "StoreType                      0\n",
      "Assortment                     0\n",
      "CompetitionDistance            3\n",
      "CompetitionOpenSinceMonth    354\n",
      "CompetitionOpenSinceYear     354\n",
      "Promo2                         0\n",
      "Promo2SinceWeek              544\n",
      "Promo2SinceYear              544\n",
      "PromoInterval                544\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Missing values\n",
    "print(train.isnull().sum(),test.isnull().sum(),store.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.drop([\"Customers\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c' 'a' 'd' 'b']\n",
      "['a' 'c' 'b']\n",
      "['0' 'a' 'b' 'c']\n"
     ]
    }
   ],
   "source": [
    "print(store.StoreType.unique())\n",
    "print(store.Assortment.unique())\n",
    "print(train.StateHoliday.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat = {\"0\": 0, \"a\": 1, \"b\": 2, \"c\": 3, \"d\": 4}\n",
    "store.StoreType.replace(cat, inplace=True)\n",
    "store.Assortment.replace(cat, inplace=True)\n",
    "train.StateHoliday.replace(cat, inplace=True)\n",
    "test.StateHoliday.replace(cat, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[\"Year\"] = train.Date.dt.year\n",
    "train[\"Month\"] = train.Date.dt.month\n",
    "train[\"Day\"] = train.Date.dt.day\n",
    "train[\"WeekOfYear\"] = train.Date.dt.weekofyear\n",
    "#\n",
    "test[\"Year\"] = test.Date.dt.year\n",
    "test[\"Month\"] = test.Date.dt.month\n",
    "test[\"Day\"] = test.Date.dt.day\n",
    "test[\"WeekOfYear\"] = test.Date.dt.weekofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Merging with store data\n",
    "train = train.merge(store, on=\"Store\")\n",
    "test = test.merge(store, on=\"Store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Competition distance\n",
    "train.loc[train.CompetitionDistance.isnull(),\"CompetitionDistance\"]=0\n",
    "test.loc[test.CompetitionDistance.isnull(),\"CompetitionDistance\"]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We introduce new variable with the Integer representing deltaT (months) between the date of sale and the date the competition has began\n",
    "train[\"CompetitionSince\"] = 12*(train.Date.dt.year - train.CompetitionOpenSinceYear)+(train.Date.dt.month-train.CompetitionOpenSinceMonth)\n",
    "test[\"CompetitionSince\"] = 12*(test.Date.dt.year - test.CompetitionOpenSinceYear)+(test.Date.dt.month-test.CompetitionOpenSinceMonth)\n",
    "train.loc[train.CompetitionSince.isnull(),\"CompetitionSince\"]=0\n",
    "test.loc[test.CompetitionSince.isnull(),\"CompetitionSince\"]=0\n",
    "\n",
    "train = train.drop([\"CompetitionOpenSinceMonth\",\"CompetitionOpenSinceYear\"], axis=1)\n",
    "test = test.drop([\"CompetitionOpenSinceMonth\",\"CompetitionOpenSinceYear\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#As we did for CompetitionSince variable, we create a new variable representing deltaT \n",
    "train[\"Promo2Since\"] = 12* (train.Date.dt.year - train.Promo2SinceYear)+(train.Date.dt.weekofyear-train.Promo2SinceWeek) / 4.0\n",
    "test[\"Promo2Since\"] = 12* (test.Date.dt.year - test.Promo2SinceYear)+(test.Date.dt.weekofyear-test.Promo2SinceWeek) / 4.0\n",
    "\n",
    "train[\"Promo2Since\"] = train.Promo2Since.apply(lambda x: x if x > 0 else 0)\n",
    "test[\"Promo2Since\"] = test.Promo2Since.apply(lambda x: x if x > 0 else 0)\n",
    "\n",
    "train.loc[train.Promo2SinceYear.isnull(), \"Promo2Since\"] = 0\n",
    "test.loc[test.Promo2SinceYear.isnull(), \"Promo2Since\"] = 0\n",
    "\n",
    "train = train.drop([\"Promo2SinceWeek\", \"Promo2SinceYear\"], axis=1)\n",
    "test = test.drop([\"Promo2SinceWeek\", \"Promo2SinceYear\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'Jan,Apr,Jul,Oct' 'Feb,May,Aug,Nov' 'Mar,Jun,Sept,Dec']\n"
     ]
    }
   ],
   "source": [
    "#For promoInterval \n",
    "month_str = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun',7:'Jul', 8:'Aug', 9:'Sept', 10:'Oct', 11:'Nov', 12:'Dec'}\n",
    "print(train.PromoInterval.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We introduce a new variable that Indicate that sales on that day are in promo interval\n",
    "def transform_promo_interval(data):\n",
    "    data['monthStr'] = data.Month.map(month_str)\n",
    "    #\n",
    "    data.loc[data.PromoInterval.isnull(), \"PromoInterval\"] = ''\n",
    "    #\n",
    "    data['IsPromoMonth'] = 0\n",
    "    #\n",
    "    for interval in data.PromoInterval.unique():\n",
    "        if interval != '':\n",
    "            for m in interval.split(','):\n",
    "                data.loc[(data.monthStr == m) & (data.PromoInterval == interval), 'IsPromoMonth'] = 1\n",
    "    data = data.drop([\"PromoInterval\"], axis=1) \n",
    "    data = data.drop([\"monthStr\"], axis=1) \n",
    "    return data\n",
    "train = transform_promo_interval(train)\n",
    "test = transform_promo_interval(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.drop([\"Date\"], axis=1)\n",
    "test = test.drop([\"Date\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmspe_xg(yhat, y):\n",
    "    y =np.exp(y.get_label())\n",
    "    yhat = np.exp(yhat)\n",
    "    return \"rmspe\", rmspe(y, yhat)\n",
    "def rmspe(y, yhat):\n",
    "    return np.sqrt(np.mean(((y - yhat) / y) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Data to enter to the optimization algorithm\n",
    "train1=train\n",
    "#\n",
    "train1 = train.drop([\"Sales\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store                    int32\n",
       "DayOfWeek                int32\n",
       "Open                     int32\n",
       "Promo                    int32\n",
       "StateHoliday             int64\n",
       "SchoolHoliday            int32\n",
       "Year                     int64\n",
       "Month                    int64\n",
       "Day                      int64\n",
       "WeekOfYear               int64\n",
       "StoreType                int64\n",
       "Assortment               int64\n",
       "CompetitionDistance    float64\n",
       "Promo2                   int32\n",
       "CompetitionSince       float64\n",
       "Promo2Since            float64\n",
       "IsPromoMonth             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain = xgboost.DMatrix(train1, np.log(train.Sales))                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.186022</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>8.186022</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.104347</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>8.104345</td>\n",
       "      <td>0.000094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.023490</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>8.023487</td>\n",
       "      <td>0.000084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.943441</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>7.943436</td>\n",
       "      <td>0.000082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.864205</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>7.864200</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.785756</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>7.785749</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.708102</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>7.708093</td>\n",
       "      <td>0.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.631226</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>7.631219</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.555123</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>7.555116</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.479771</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>7.479764</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.405176</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>7.405170</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.331339</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>7.331333</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.258226</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>7.258221</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.185850</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>7.185844</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.114207</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>7.114195</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.043276</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>7.043264</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.973060</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>6.973050</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.903536</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>6.903528</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.834712</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>6.834704</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.766581</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>6.766570</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6.699122</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>6.699114</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6.632351</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>6.632344</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6.566244</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>6.566235</td>\n",
       "      <td>0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6.500808</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>6.500802</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.436032</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>6.436027</td>\n",
       "      <td>0.000056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6.371906</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>6.371902</td>\n",
       "      <td>0.000056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6.308414</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>6.308411</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6.245552</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>6.245546</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6.183326</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>6.183320</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6.121711</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>6.121705</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>0.193654</td>\n",
       "      <td>0.002639</td>\n",
       "      <td>0.190896</td>\n",
       "      <td>0.002474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>0.193613</td>\n",
       "      <td>0.002621</td>\n",
       "      <td>0.190853</td>\n",
       "      <td>0.002465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>0.193561</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.190800</td>\n",
       "      <td>0.002448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>0.193511</td>\n",
       "      <td>0.002615</td>\n",
       "      <td>0.190747</td>\n",
       "      <td>0.002455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>0.193376</td>\n",
       "      <td>0.002560</td>\n",
       "      <td>0.190611</td>\n",
       "      <td>0.002393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.193248</td>\n",
       "      <td>0.002548</td>\n",
       "      <td>0.190482</td>\n",
       "      <td>0.002367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>0.193186</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.190417</td>\n",
       "      <td>0.002363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>0.193105</td>\n",
       "      <td>0.002504</td>\n",
       "      <td>0.190336</td>\n",
       "      <td>0.002316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>0.193031</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.190260</td>\n",
       "      <td>0.002336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>0.192950</td>\n",
       "      <td>0.002478</td>\n",
       "      <td>0.190179</td>\n",
       "      <td>0.002297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>0.192877</td>\n",
       "      <td>0.002520</td>\n",
       "      <td>0.190102</td>\n",
       "      <td>0.002324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>0.192773</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.189996</td>\n",
       "      <td>0.002285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>0.192712</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>0.189932</td>\n",
       "      <td>0.002323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>0.192570</td>\n",
       "      <td>0.002449</td>\n",
       "      <td>0.189789</td>\n",
       "      <td>0.002256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>0.192522</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.189738</td>\n",
       "      <td>0.002272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.192474</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.189686</td>\n",
       "      <td>0.002282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>0.192409</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>0.189617</td>\n",
       "      <td>0.002313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>0.192305</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>0.189510</td>\n",
       "      <td>0.002294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>0.192199</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.189401</td>\n",
       "      <td>0.002275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>0.192103</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>0.189302</td>\n",
       "      <td>0.002282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>0.191991</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.002238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>0.191879</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>0.189075</td>\n",
       "      <td>0.002225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>0.191725</td>\n",
       "      <td>0.002450</td>\n",
       "      <td>0.188921</td>\n",
       "      <td>0.002264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>0.191683</td>\n",
       "      <td>0.002437</td>\n",
       "      <td>0.188877</td>\n",
       "      <td>0.002249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0.191577</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.188767</td>\n",
       "      <td>0.002239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.191494</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>0.188682</td>\n",
       "      <td>0.002276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.191427</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.188613</td>\n",
       "      <td>0.002278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.191389</td>\n",
       "      <td>0.002507</td>\n",
       "      <td>0.188574</td>\n",
       "      <td>0.002288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.191340</td>\n",
       "      <td>0.002486</td>\n",
       "      <td>0.188523</td>\n",
       "      <td>0.002268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.191285</td>\n",
       "      <td>0.002504</td>\n",
       "      <td>0.188466</td>\n",
       "      <td>0.002279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     test-rmse-mean  test-rmse-std  train-rmse-mean  train-rmse-std\n",
       "0          8.186022       0.000367         8.186022        0.000089\n",
       "1          8.104347       0.000363         8.104345        0.000094\n",
       "2          8.023490       0.000373         8.023487        0.000084\n",
       "3          7.943441       0.000377         7.943436        0.000082\n",
       "4          7.864205       0.000377         7.864200        0.000083\n",
       "5          7.785756       0.000395         7.785749        0.000074\n",
       "6          7.708102       0.000409         7.708093        0.000068\n",
       "7          7.631226       0.000405         7.631219        0.000072\n",
       "8          7.555123       0.000399         7.555116        0.000078\n",
       "9          7.479771       0.000399         7.479764        0.000079\n",
       "10         7.405176       0.000403         7.405170        0.000075\n",
       "11         7.331339       0.000405         7.331333        0.000072\n",
       "12         7.258226       0.000405         7.258221        0.000069\n",
       "13         7.185850       0.000402         7.185844        0.000075\n",
       "14         7.114207       0.000406         7.114195        0.000071\n",
       "15         7.043276       0.000406         7.043264        0.000074\n",
       "16         6.973060       0.000399         6.973050        0.000078\n",
       "17         6.903536       0.000403         6.903528        0.000071\n",
       "18         6.834712       0.000404         6.834704        0.000076\n",
       "19         6.766581       0.000410         6.766570        0.000064\n",
       "20         6.699122       0.000408         6.699114        0.000063\n",
       "21         6.632351       0.000412         6.632344        0.000057\n",
       "22         6.566244       0.000410         6.566235        0.000061\n",
       "23         6.500808       0.000422         6.500802        0.000057\n",
       "24         6.436032       0.000435         6.436027        0.000056\n",
       "25         6.371906       0.000430         6.371902        0.000056\n",
       "26         6.308414       0.000420         6.308411        0.000074\n",
       "27         6.245552       0.000418         6.245546        0.000074\n",
       "28         6.183326       0.000415         6.183320        0.000074\n",
       "29         6.121711       0.000416         6.121705        0.000074\n",
       "..              ...            ...              ...             ...\n",
       "970        0.193654       0.002639         0.190896        0.002474\n",
       "971        0.193613       0.002621         0.190853        0.002465\n",
       "972        0.193561       0.002603         0.190800        0.002448\n",
       "973        0.193511       0.002615         0.190747        0.002455\n",
       "974        0.193376       0.002560         0.190611        0.002393\n",
       "975        0.193248       0.002548         0.190482        0.002367\n",
       "976        0.193186       0.002555         0.190417        0.002363\n",
       "977        0.193105       0.002504         0.190336        0.002316\n",
       "978        0.193031       0.002538         0.190260        0.002336\n",
       "979        0.192950       0.002478         0.190179        0.002297\n",
       "980        0.192877       0.002520         0.190102        0.002324\n",
       "981        0.192773       0.002493         0.189996        0.002285\n",
       "982        0.192712       0.002514         0.189932        0.002323\n",
       "983        0.192570       0.002449         0.189789        0.002256\n",
       "984        0.192522       0.002464         0.189738        0.002272\n",
       "985        0.192474       0.002470         0.189686        0.002282\n",
       "986        0.192409       0.002492         0.189617        0.002313\n",
       "987        0.192305       0.002475         0.189510        0.002294\n",
       "988        0.192199       0.002472         0.189401        0.002275\n",
       "989        0.192103       0.002496         0.189302        0.002282\n",
       "990        0.191991       0.002441         0.189189        0.002238\n",
       "991        0.191879       0.002425         0.189075        0.002225\n",
       "992        0.191725       0.002450         0.188921        0.002264\n",
       "993        0.191683       0.002437         0.188877        0.002249\n",
       "994        0.191577       0.002439         0.188767        0.002239\n",
       "995        0.191494       0.002479         0.188682        0.002276\n",
       "996        0.191427       0.002493         0.188613        0.002278\n",
       "997        0.191389       0.002507         0.188574        0.002288\n",
       "998        0.191340       0.002486         0.188523        0.002268\n",
       "999        0.191285       0.002504         0.188466        0.002279\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross val \n",
    "params = {\"objective\": \"reg:linear\",\n",
    "          \"booster\": \"gbtree\",\n",
    "          \"eta\": 0.01,\n",
    "          \"max_depth\": 10,\n",
    "          \"subsample\": 0.8,\n",
    "          \"colsample_bytree\": 0.4,\n",
    "          \"silent\": 1,\n",
    "          \"seed\": 1301}\n",
    "num_boost_round = 1000\n",
    "cv_results = xgboost.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    metrics={'rmse'},\n",
    "    early_stopping_rounds=5\n",
    ")\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we will only try to improve the mean test RMSE. We can get the best RMSE score from cv with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19128539999999999"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['test-rmse-mean'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters max_depth and min_child_weight (tree parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can try wider intervals with a larger step between\n",
    "# following ranges.\n",
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(9,12)\n",
    "    for min_child_weight in range(5,8)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=9, min_child_weight=5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-87daa07cb87f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mnfold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'rmse'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     )\n\u001b[1;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\hp\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks)\u001b[0m\n\u001b[1;32m    398\u001b[0m                            evaluation_result_list=None))\n\u001b[1;32m    399\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mfold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\hp\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, iteration, fobj)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[1;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\hp\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define initial best params and RMSE\n",
    "min_rmse = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "\n",
    "    # Run CV\n",
    "    cv_results = xgboost.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'rmse'},\n",
    "        early_stopping_rounds=50\n",
    "    )\n",
    "\n",
    "    # Update best RMSE\n",
    "    mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tRMSE {} for {} rounds\".format(mean_rmse, boost_rounds))\n",
    "    if mean_rmse < min_rmse:\n",
    "        min_rmse = mean_rmse\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "\n",
    "print(\"Best params: {}, {}, RMSE: {}\".format(best_params[0], best_params[1], min_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params['max_depth'] = \n",
    "params['min_child_weight'] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define initial best params and RMSE\n",
    "min_rmse = float(\"Inf\")\n",
    "best_params = None\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "\n",
    "     # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "\n",
    "    # Run CV\n",
    "    cv_results = xgboost.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'rmse'},\n",
    "        early_stopping_rounds=50\n",
    "    )\n",
    "\n",
    "    # Update best RMSE\n",
    "    mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tRMSE {} for {} rounds\".format(mean_rmse, boost_rounds))\n",
    "    if mean_rmse < min_rmse:\n",
    "        min_rmse = mean_rmse\n",
    "        best_params = (subsample,colsample)\n",
    "\n",
    "print(\"Best params: {}, {}, RMSE: {}\".format(best_params[0], best_params[1], min_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params['subsample'] = \n",
    "params['colsample_bytree'] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter ETA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ETA parameter controls the learning rate. It corresponds to the shrinkage of the weights associated to features after each round, in other words it defines the amount of \"correction\" we make at each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define initial best params and RMSE\n",
    "min_rmse = float(\"Inf\")\n",
    "best_params = None\n",
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "\n",
    "\n",
    "    \n",
    "    # We update our parameters\n",
    "    params['eta'] = eta\n",
    "\n",
    "    # Run CV\n",
    "    %time cv_results = xgboost.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'rmse'},\n",
    "        early_stopping_rounds=50\n",
    "    )\n",
    "\n",
    "    # Update best RMSE\n",
    "    mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tRMSE {} for {} rounds\".format(mean_rmse, boost_rounds))\n",
    "    if mean_rmse < min_rmse:\n",
    "        min_rmse = mean_rmse\n",
    "        best_params = eta\n",
    "\n",
    "print(\"Best params: {}, {}, RMSE: {}\".format(best_params[0], best_params[1], min_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params['eta'] ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
